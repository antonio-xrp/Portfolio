{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27ab098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/11 11:23:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"python spark SQL basic example\")\\\n",
    "        .config(\"spark.some.config.option\", \"some-value\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b8d64d",
   "metadata": {},
   "source": [
    "Spark tiene sus propios datos internos que no son exactamente los mismo que lo de tipo python (int, float, str), spark usa su propio motor llamado catalyst. que transforma el codigo que tu escribes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e7478fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[(number + 10): bigint]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creamos una columna de nÃ¹meros del 0 al 499 y le damos de nombre \"number\"\n",
    "df = spark.range(500).toDF(\"number\")\n",
    "#selecciona la col number y suma 10 a cada valor, es como for\n",
    "df.select(df['number']+ 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f82b02a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.collect of DataFrame[id: bigint]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.range(2).collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63496259",
   "metadata": {},
   "source": [
    "### ðŸ§  Â¿QuÃ© son los Spark Types?\n",
    "Spark trabaja con sus propios \"tipos de datos\". Son como etiquetas que le dicen a Spark quÃ© tipo de datos hay en cada columna de una tabla.\n",
    "\n",
    "Ejemplo: si tienes una tabla como esta:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1878098",
   "metadata": {},
   "source": [
    "| nombre    | edad | cliente |\n",
    "| --------- | ---- | ------- |\n",
    "| \"Antonio\" | 35   | True    |\n",
    "\n",
    "\n",
    "Spark necesita saber:\n",
    "\n",
    "- \"nombre\" es texto â†’ tipo StringType\n",
    "\n",
    "- \"edad\" es nÃºmero entero â†’ tipo IntegerType\n",
    "\n",
    "- \"cliente\" es verdadero/falso â†’ tipo BooleanType\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32414a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "nombre = StringType()\n",
    "edad = IntegerType()\n",
    "cliente = BooleanType()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1c3b5c",
   "metadata": {},
   "source": [
    "| Spark Type        | Tipo de Python    | Â¿Para quÃ© se usa?                   |\n",
    "| ----------------- | ----------------- | ----------------------------------- |\n",
    "| `ByteType()`      | int               | NÃºmeros muy pequeÃ±os (-128 a 127)   |\n",
    "| `ShortType()`     | int               | NÃºmeros pequeÃ±os (-32 mil a 32 mil) |\n",
    "| `IntegerType()`   | int               | NÃºmeros enteros normales            |\n",
    "| `LongType()`      | int o long        | NÃºmeros enteros grandes             |\n",
    "| `FloatType()`     | float             | Decimales livianos                  |\n",
    "| `DoubleType()`    | float             | Decimales mÃ¡s precisos              |\n",
    "| `DecimalType()`   | decimal.Decimal   | Decimales exactos (ej. dinero)      |\n",
    "| `StringType()`    | str               | Textos o palabras                   |\n",
    "| `BooleanType()`   | bool              | Verdadero o falso                   |\n",
    "| `DateType()`      | datetime.date     | Fechas (solo dÃ­a, mes, aÃ±o)         |\n",
    "| `TimestampType()` | datetime.datetime | Fechas con hora incluida            |\n",
    "| `ArrayType()`     | list o tuple      | Lista de elementos                  |\n",
    "| `MapType()`       | dict              | Diccionario (clave\\:valor)          |\n",
    "| `StructType()`    | lista de columnas | Define una tabla completa           |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
